{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/garvsharmxa/3D_Model_Reconstructions/blob/main/3Dify_Image_to_Dimension.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eclLG4xlJRIE"
      },
      "source": [
        "# **3D Model Reconstruction For Blender**:\n",
        "![](https://shunsukesaito.github.io/PIFuHD/resources/images/pifuhd.gif)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ta4xq8JrCkRY"
      },
      "source": [
        "## **Note**\n",
        "Make sure that your runtime type is 'Python 3 with GPU acceleration'. To do so, go to Edit > Notebook settings > Hardware Accelerator > Select \"GPU\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zKVDxEXCZ4S"
      },
      "source": [
        "## **Requirements**\n",
        "- Python 3\n",
        "- IPython\n",
        "- PyTorch\n",
        "- PIFuHD\n",
        "- Torch\n",
        "- TorchVision\n",
        "- json\n",
        "- PIL\n",
        "- skimage\n",
        "- numpy\n",
        "- cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K097_hzLCs-Z"
      },
      "source": [
        "## **Help! I'm new to Google Colab**\n",
        "\n",
        "You can check out the following youtube video on how to upload your own picture and run GHD. **Note that with new update, you can upload your own picture more easily with GUI down below.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "collapsed": true,
        "id": "Bbzauji1E2tm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b7862a5-e125-4910-ed7e-5b0658c401f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Downloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.1.1\n",
            "Cloning into 'pifuhd'...\n",
            "remote: Enumerating objects: 222, done.\u001b[K\n",
            "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 222 (delta 20), reused 20 (delta 20), pack-reused 200 (from 1)\u001b[K\n",
            "Receiving objects: 100% (222/222), 399.83 KiB | 11.42 MiB/s, done.\n",
            "Resolving deltas: 100% (113/113), done.\n",
            "Cloning into 'lightweight-human-pose-estimation.pytorch'...\n",
            "remote: Enumerating objects: 124, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 124 (delta 20), reused 18 (delta 18), pack-reused 91 (from 2)\u001b[K\n",
            "Receiving objects: 100% (124/124), 230.37 KiB | 6.78 MiB/s, done.\n",
            "Resolving deltas: 100% (52/52), done.\n",
            "/content/lightweight-human-pose-estimation.pytorch\n",
            "--2025-07-30 14:59:57--  https://download.01.org/opencv/openvino_training_extensions/models/human_pose_estmation/checkpoint_iter_370000.pth\n",
            "Resolving download.01.org (download.01.org)... 184.24.162.127, 2a02:26f0:1180:188::a87, 2a02:26f0:1180:19c::a87\n",
            "Connecting to download.01.org (download.01.org)|184.24.162.127|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-07-30 14:59:58 ERROR 404: Not Found.\n",
            "\n",
            "/content/pifuhd\n",
            "+ mkdir -p checkpoints\n",
            "+ cd checkpoints\n",
            "+ wget https://dl.fbaipublicfiles.com/pifuhd/checkpoints/pifuhd.pt pifuhd.pt\n",
            "--2025-07-30 14:59:58--  https://dl.fbaipublicfiles.com/pifuhd/checkpoints/pifuhd.pt\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 18.239.50.18, 18.239.50.9, 18.239.50.104, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|18.239.50.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1548375177 (1.4G) [application/octet-stream]\n",
            "Saving to: ‚Äòpifuhd.pt‚Äô\n",
            "\n",
            "pifuhd.pt           100%[===================>]   1.44G   130MB/s    in 7.6s    \n",
            "\n",
            "2025-07-30 15:00:06 (193 MB/s) - ‚Äòpifuhd.pt‚Äô saved [1548375177/1548375177]\n",
            "\n",
            "--2025-07-30 15:00:06--  http://pifuhd.pt/\n",
            "Resolving pifuhd.pt (pifuhd.pt)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‚Äòpifuhd.pt‚Äô\n",
            "FINISHED --2025-07-30 15:00:06--\n",
            "Total wall clock time: 8.2s\n",
            "Downloaded: 1 files, 1.4G in 7.6s (193 MB/s)\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==2.4.1\n",
            "  Downloading torch-2.4.1-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1) (4.14.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4.1)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4.1)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.1)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4.1)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4.1)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4.1)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4.1)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4.1)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.1)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4.1)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.0.0 (from torch==2.4.1)\n",
            "  Downloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.1) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.4.1) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.4.1) (1.3.0)\n",
            "Downloading torch-2.4.1-cp311-cp311-manylinux1_x86_64.whl (797.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m797.1/797.1 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m148.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m168.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch\n",
            "\u001b[2K  Attempting uninstall: triton\n",
            "\u001b[2K    Found existing installation: triton 3.2.0\n",
            "\u001b[2K    Uninstalling triton-3.2.0:\n",
            "\u001b[2K      Successfully uninstalled triton-3.2.0\n",
            "\u001b[2K  Attempting uninstall: nvidia-nvtx-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "\u001b[2K    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "\u001b[2K      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "\u001b[2K  Attempting uninstall: nvidia-nccl-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "\u001b[2K    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "\u001b[2K      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "\u001b[2K  Attempting uninstall: nvidia-cusparse-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "\u001b[2K    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "\u001b[2K  Attempting uninstall: nvidia-curand-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "\u001b[2K    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "\u001b[2K      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "\u001b[2K  Attempting uninstall: nvidia-cufft-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "\u001b[2K    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "\u001b[2K  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "\u001b[2K    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "\u001b[2K  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "\u001b[2K    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "\u001b[2K  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "\u001b[2K    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "\u001b[2K  Attempting uninstall: nvidia-cublas-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "\u001b[2K    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "\u001b[2K  Attempting uninstall: nvidia-cusolver-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "\u001b[2K    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[2K  Attempting uninstall: nvidia-cudnn-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "\u001b[2K    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "\u001b[2K  Attempting uninstall: torch\n",
            "\u001b[2K    Found existing installation: torch 2.6.0+cu124\n",
            "\u001b[2K    Uninstalling torch-2.6.0+cu124:\n",
            "\u001b[2K      Successfully uninstalled torch-2.6.0+cu124\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13/13\u001b[0m [torch]\n",
            "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.4.1 which is incompatible.\n",
            "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.4.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.4.1 triton-3.0.0\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torchvision==0.19.1\n",
            "  Downloading torchvision-0.19.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.19.1) (2.0.2)\n",
            "Requirement already satisfied: torch==2.4.1 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.19.1) (2.4.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.19.1) (11.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1->torchvision==0.19.1) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1->torchvision==0.19.1) (4.14.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1->torchvision==0.19.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1->torchvision==0.19.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1->torchvision==0.19.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1->torchvision==0.19.1) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1->torchvision==0.19.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1->torchvision==0.19.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1->torchvision==0.19.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1->torchvision==0.19.1) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1->torchvision==0.19.1) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1->torchvision==0.19.1) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1->torchvision==0.19.1) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1->torchvision==0.19.1) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1->torchvision==0.19.1) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1->torchvision==0.19.1) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1->torchvision==0.19.1) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1->torchvision==0.19.1) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.1->torchvision==0.19.1) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.4.1->torchvision==0.19.1) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.4.1->torchvision==0.19.1) (1.3.0)\n",
            "Downloading torchvision-0.19.1-cp311-cp311-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m97.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchvision\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "Successfully installed torchvision-0.19.1\n",
            "Collecting git+https://github.com/facebookresearch/pytorch3d.git\n",
            "  Cloning https://github.com/facebookresearch/pytorch3d.git to /tmp/pip-req-build-s6gh61qs\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/pytorch3d.git /tmp/pip-req-build-s6gh61qs\n",
            "  Resolved https://github.com/facebookresearch/pytorch3d.git to commit 5043d15361d16a7093b4b60572c5f730c6c83308\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting iopath (from pytorch3d==0.7.8)\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from iopath->pytorch3d==0.7.8) (4.67.1)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from iopath->pytorch3d==0.7.8) (4.14.1)\n",
            "Collecting portalocker (from iopath->pytorch3d==0.7.8)\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Building wheels for collected packages: pytorch3d, iopath\n",
            "\u001b[33m  DEPRECATION: Building 'pytorch3d' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'pytorch3d'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
            "\u001b[0m  Building wheel for pytorch3d (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch3d: filename=pytorch3d-0.7.8-cp311-cp311-linux_x86_64.whl size=58246371 sha256=17b85db51daaec16a53d6691a5ac19ee0c1fcbef2951b72412a1ab17ad21b14b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-8cinbd8v/wheels/39/02/3b/eab9735f985044755f4e6d9e8473bfb8b68dc63723658e2ac2\n",
            "\u001b[33m  DEPRECATION: Building 'iopath' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'iopath'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
            "\u001b[0m  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31527 sha256=ae287cd5272d2d61da9eaa26b04cde7c65ed2a03dfd14d7372c8bfa3c94acdbb\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/5e/16/6117f8fe7e9c0c161a795e10d94645ebcf301ccbd01f66d8ec\n",
            "Successfully built pytorch3d iopath\n",
            "Installing collected packages: portalocker, iopath, pytorch3d\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3/3\u001b[0m [pytorch3d]\n",
            "\u001b[1A\u001b[2KSuccessfully installed iopath-0.1.10 portalocker-3.2.0 pytorch3d-0.7.8\n",
            "/content/lightweight-human-pose-estimation.pytorch\n"
          ]
        }
      ],
      "source": [
        "!pip3 install --upgrade pip\n",
        "\n",
        "#@title STEP1: Execute to Setup Pifuhd\n",
        "!git clone https://github.com/facebookresearch/pifuhd\n",
        "!git clone https://github.com/Daniil-Osokin/lightweight-human-pose-estimation.pytorch.git\n",
        "\n",
        "%cd /content/lightweight-human-pose-estimation.pytorch/\n",
        "!wget https://download.01.org/opencv/openvino_training_extensions/models/human_pose_estmation/checkpoint_iter_370000.pth\n",
        "\n",
        "%cd /content/pifuhd/\n",
        "!sh ./scripts/download_trained_model.sh\n",
        "\n",
        "\n",
        "!pip install 'torch==2.4.1' -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install 'torchvision==0.19.1' -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install 'git+https://github.com/facebookresearch/pytorch3d.git'\n",
        "\n",
        "\n",
        "\n",
        "%cd /content/lightweight-human-pose-estimation.pytorch/\n",
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "from models.with_mobilenet import PoseEstimationWithMobileNet\n",
        "from modules.keypoints import extract_keypoints, group_keypoints\n",
        "from modules.load_state import load_state\n",
        "from modules.pose import Pose, track_poses\n",
        "import demo\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def get_rect(net, images, height_size):\n",
        "    net = net.eval()\n",
        "\n",
        "    stride = 8\n",
        "    upsample_ratio = 4\n",
        "    num_keypoints = Pose.num_kpts\n",
        "    previous_poses = []\n",
        "    delay = 33\n",
        "    for image in images:\n",
        "        rect_path = image.replace('.%s' % (image.split('.')[-1]), '_rect.txt')\n",
        "        img = cv2.imread(image, cv2.IMREAD_COLOR)\n",
        "        orig_img = img.copy()\n",
        "        orig_img = img.copy()\n",
        "        heatmaps, pafs, scale, pad = demo.infer_fast(net, img, height_size, stride, upsample_ratio, cpu=False)\n",
        "\n",
        "        total_keypoints_num = 0\n",
        "        all_keypoints_by_type = []\n",
        "        for kpt_idx in range(num_keypoints):  # 19th for bg\n",
        "            total_keypoints_num += extract_keypoints(heatmaps[:, :, kpt_idx], all_keypoints_by_type, total_keypoints_num)\n",
        "\n",
        "        pose_entries, all_keypoints = group_keypoints(all_keypoints_by_type, pafs)\n",
        "        for kpt_id in range(all_keypoints.shape[0]):\n",
        "            all_keypoints[kpt_id, 0] = (all_keypoints[kpt_id, 0] * stride / upsample_ratio - pad[1]) / scale\n",
        "            all_keypoints[kpt_id, 1] = (all_keypoints[kpt_id, 1] * stride / upsample_ratio - pad[0]) / scale\n",
        "        current_poses = []\n",
        "\n",
        "        rects = []\n",
        "        for n in range(len(pose_entries)):\n",
        "            if len(pose_entries[n]) == 0:\n",
        "                continue\n",
        "            pose_keypoints = np.ones((num_keypoints, 2), dtype=np.int32) * -1\n",
        "            valid_keypoints = []\n",
        "            for kpt_id in range(num_keypoints):\n",
        "                if pose_entries[n][kpt_id] != -1.0:  # keypoint was found\n",
        "                    pose_keypoints[kpt_id, 0] = int(all_keypoints[int(pose_entries[n][kpt_id]), 0])\n",
        "                    pose_keypoints[kpt_id, 1] = int(all_keypoints[int(pose_entries[n][kpt_id]), 1])\n",
        "                    valid_keypoints.append([pose_keypoints[kpt_id, 0], pose_keypoints[kpt_id, 1]])\n",
        "            valid_keypoints = np.array(valid_keypoints)\n",
        "\n",
        "            if pose_entries[n][10] != -1.0 or pose_entries[n][13] != -1.0:\n",
        "              pmin = valid_keypoints.min(0)\n",
        "              pmax = valid_keypoints.max(0)\n",
        "\n",
        "              center = (0.5 * (pmax[:2] + pmin[:2])).astype(np.int)\n",
        "              radius = int(0.65 * max(pmax[0]-pmin[0], pmax[1]-pmin[1]))\n",
        "            elif pose_entries[n][10] == -1.0 and pose_entries[n][13] == -1.0 and pose_entries[n][8] != -1.0 and pose_entries[n][11] != -1.0:\n",
        "              # if leg is missing, use pelvis to get cropping\n",
        "              center = (0.5 * (pose_keypoints[8] + pose_keypoints[11])).astype(np.int)\n",
        "              radius = int(1.45*np.sqrt(((center[None,:] - valid_keypoints)**2).sum(1)).max(0))\n",
        "              center[1] += int(0.05*radius)\n",
        "            else:\n",
        "              center = np.array([img.shape[1]//2,img.shape[0]//2])\n",
        "              radius = max(img.shape[1]//2,img.shape[0]//2)\n",
        "\n",
        "            x1 = center[0] - radius\n",
        "            y1 = center[1] - radius\n",
        "\n",
        "            rects.append([x1, y1, 2*radius, 2*radius])\n",
        "\n",
        "        np.savetxt(rect_path, np.array(rects), fmt='%d')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaiNm_QAyx7h"
      },
      "source": [
        "# **Using Form Internet**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "collapsed": true,
        "id": "8KHPtNWwObj-"
      },
      "outputs": [],
      "source": [
        "#@title **Uploadind Image From Internet**\n",
        "#@markdown * Find an image on the Internet\n",
        "#@markdown * Right click and copy image address\n",
        "#@markdown * Paste the image address to image_url\n",
        "image_url = 'https://toppng.com/uploads/preview/transparent-human-11550225796ipkgyynyvt.png' #@param {type:\"string\"}\n",
        "path = '/content/pifuhd/sample_images/webImg'\n",
        "\n",
        "#empty the folder\n",
        "!rm -rf '/content/pifuhd/sample_images'\n",
        "!mkdir '/content/pifuhd/sample_images'\n",
        "\n",
        "!wget {image_url} -O {path}\n",
        "import cv2\n",
        "img = cv2.imread(path)\n",
        "cv2.imwrite('/content/pifuhd/sample_images/webImg.png', img)\n",
        "!rm -f '$path'\n",
        "\n",
        "import os\n",
        "image_path = '/content/pifuhd/sample_images/webImg.png'\n",
        "image_dir = os.path.dirname(image_path)\n",
        "file_name = os.path.splitext(os.path.basename(image_path))[0]\n",
        "\n",
        "# output pathes\n",
        "obj_path = '/content/pifuhd/results/pifuhd_final/recon/result_%s_256.obj' % file_name\n",
        "out_img_path = '/content/pifuhd/results/pifuhd_final/recon/result_%s_256.png' % file_name\n",
        "video_path = '/content/pifuhd/results/pifuhd_final/recon/result_%s_256.mp4' % file_name\n",
        "video_display_path = '/content/pifuhd/results/pifuhd_final/result_%s_256_display.mp4' % file_name\n",
        "\n",
        "# Make sure we're in the right directory and download the checkpoint\n",
        "%cd /content/lightweight-human-pose-estimation.pytorch/\n",
        "\n",
        "def get_rect(net, images, height_size):\n",
        "    net = net.eval()\n",
        "    stride = 8\n",
        "    upsample_ratio = 4\n",
        "    num_keypoints = Pose.num_kpts\n",
        "    previous_poses = []\n",
        "    delay = 33\n",
        "\n",
        "    for image in images:\n",
        "        rect_path = image.replace('.%s' % (image.split('.')[-1]), '_rect.txt')\n",
        "        img = cv2.imread(image, cv2.IMREAD_COLOR)\n",
        "        orig_img = img.copy()\n",
        "        orig_img = img.copy()\n",
        "        heatmaps, pafs, scale, pad = demo.infer_fast(net, img, height_size, stride, upsample_ratio, cpu=False)\n",
        "\n",
        "        total_keypoints_num = 0\n",
        "        all_keypoints_by_type = []\n",
        "        for kpt_idx in range(num_keypoints):  # 19th for bg\n",
        "            total_keypoints_num += extract_keypoints(heatmaps[:, :, kpt_idx], all_keypoints_by_type, total_keypoints_num)\n",
        "\n",
        "        pose_entries, all_keypoints = group_keypoints(all_keypoints_by_type, pafs)\n",
        "        for kpt_id in range(all_keypoints.shape[0]):\n",
        "            all_keypoints[kpt_id, 0] = (all_keypoints[kpt_id, 0] * stride / upsample_ratio - pad[1]) / scale\n",
        "            all_keypoints[kpt_id, 1] = (all_keypoints[kpt_id, 1] * stride / upsample_ratio - pad[0]) / scale\n",
        "\n",
        "        current_poses = []\n",
        "        rects = []\n",
        "        for n in range(len(pose_entries)):\n",
        "            if len(pose_entries[n]) == 0:\n",
        "                continue\n",
        "\n",
        "            pose_keypoints = np.ones((num_keypoints, 2), dtype=np.int32) * -1  # Fixed: np.int -> np.int32\n",
        "            valid_keypoints = []\n",
        "            for kpt_id in range(num_keypoints):\n",
        "                if pose_entries[n][kpt_id] != -1.0:  # keypoint was found\n",
        "                    pose_keypoints[kpt_id, 0] = int(all_keypoints[int(pose_entries[n][kpt_id]), 0])\n",
        "                    pose_keypoints[kpt_id, 1] = int(all_keypoints[int(pose_entries[n][kpt_id]), 1])\n",
        "                    valid_keypoints.append([pose_keypoints[kpt_id, 0], pose_keypoints[kpt_id, 1]])\n",
        "\n",
        "            valid_keypoints = np.array(valid_keypoints)\n",
        "            if pose_entries[n][10] != -1.0 or pose_entries[n][13] != -1.0:\n",
        "                pmin = valid_keypoints.min(0)\n",
        "                pmax = valid_keypoints.max(0)\n",
        "                center = (0.5 * (pmax[:2] + pmin[:2])).astype(np.int32)  # Fixed: np.int -> np.int32\n",
        "                radius = int(0.65 * max(pmax[0]-pmin[0], pmax[1]-pmin[1]))\n",
        "            elif pose_entries[n][10] == -1.0 and pose_entries[n][13] == -1.0 and pose_entries[n][8] != -1.0 and pose_entries[n][11] != -1.0:\n",
        "                # if leg is missing, use pelvis to get cropping\n",
        "                center = (0.5 * (pose_keypoints[8] + pose_keypoints[11])).astype(np.int32)  # Fixed: np.int -> np.int32\n",
        "                radius = int(1.45*np.sqrt(((center[None,:] - valid_keypoints)**2).sum(1)).max(0))\n",
        "                center[1] += int(0.05*radius)\n",
        "            else:\n",
        "                center = np.array([img.shape[1]//2, img.shape[0]//2])\n",
        "                radius = max(img.shape[1]//2, img.shape[0]//2)\n",
        "\n",
        "            x1 = center[0] - radius\n",
        "            y1 = center[1] - radius\n",
        "            rects.append([x1, y1, 2*radius, 2*radius])\n",
        "\n",
        "        np.savetxt(rect_path, np.array(rects), fmt='%d')\n",
        "\n",
        "# Check if checkpoint exists, if not download it\n",
        "import os\n",
        "checkpoint_path = '/content/lightweight-human-pose-estimation.pytorch/checkpoint_iter_370000.pth'\n",
        "\n",
        "if not os.path.exists(checkpoint_path):\n",
        "    print(\"Downloading checkpoint file...\")\n",
        "    !wget https://download.01.org/opencv/openvino_training_extensions/models/human_pose_estimation/checkpoint_iter_370000.pth\n",
        "else:\n",
        "    print(\"Checkpoint file already exists\")\n",
        "\n",
        "# Now load the network with checkpoint\n",
        "net = PoseEstimationWithMobileNet()\n",
        "checkpoint = torch.load('checkpoint_iter_370000.pth', map_location='cpu')\n",
        "load_state(net, checkpoint)\n",
        "get_rect(net.cuda(), [image_path], 512)\n",
        "\n",
        "#run\n",
        "%cd /content/pifuhd/\n",
        "# Warning: all images with the corresponding rectangle files under -i will be processed.\n",
        "!python -m apps.simple_test -r 256 --use_rect -i $image_dir\n",
        "# seems that 256 is the maximum resolution that can fit into Google Colab.\n",
        "# If you want to reconstruct a higher-resolution mesh, please try with your own machine.\n",
        "\n",
        "#clear everything\n",
        "clear_output()\n",
        "#render video\n",
        "from lib.colab_util import generate_video_from_obj, set_renderer, video\n",
        "\n",
        "renderer = set_renderer()\n",
        "generate_video_from_obj(obj_path, out_img_path, video_path, renderer)\n",
        "\n",
        "# we cannot play a mp4 video generated by cv2\n",
        "!ffmpeg -i $video_path -vcodec libx264 $video_display_path -y -loglevel quiet\n",
        "video(video_display_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "OwZu1ih8wknw",
        "outputId": "1590dc81-8056-4780-994d-4b840900fce7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_33818d6d-1b92-4277-8991-bc2d9e56e724\", \"result_webImg_256.obj\", 4496933)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@title **Download 3D Model (.obj file) and Results (From Internet Image)**\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "# Define paths for internet-sourced image results\n",
        "RESULTS_PATH = '/content/pifuhd/results/pifuhd_final/recon'\n",
        "file_name = 'webImg'  # Standard naming for internet-downloaded images\n",
        "\n",
        "# Define all possible output files\n",
        "obj_path = f'{RESULTS_PATH}/result_{file_name}_256.obj'\n",
        "png_path = f'{RESULTS_PATH}/result_{file_name}_256.png'\n",
        "video_path = f'{RESULTS_PATH}/result_{file_name}_256.mp4'\n",
        "video_display_path = f'/content/pifuhd/results/pifuhd_final/result_{file_name}_256_display.mp4'\n",
        "\n",
        "print(\"üåê Downloading results from internet image processing...\")\n",
        "print(\"Checking available files...\")\n",
        "\n",
        "# Check which files exist and prepare for download\n",
        "files_to_download = []\n",
        "\n",
        "if os.path.exists(obj_path):\n",
        "    files_to_download.append(('3D Model (.obj)', obj_path))\n",
        "    print(f\"‚úì 3D model found: result_{file_name}_256.obj\")\n",
        "else:\n",
        "    print(f\"‚úó 3D model not found: result_{file_name}_256.obj\")\n",
        "\n",
        "if os.path.exists(png_path):\n",
        "    files_to_download.append(('Rendered Image (.png)', png_path))\n",
        "    print(f\"‚úì Rendered image found: result_{file_name}_256.png\")\n",
        "else:\n",
        "    print(f\"‚úó Rendered image not found: result_{file_name}_256.png\")\n",
        "\n",
        "if os.path.exists(video_display_path):\n",
        "    files_to_download.append(('3D Animation (.mp4)', video_display_path))\n",
        "    print(f\"‚úì 3D animation found: result_{file_name}_256_display.mp4\")\n",
        "elif os.path.exists(video_path):\n",
        "    files_to_download.append(('3D Animation (.mp4)', video_path))\n",
        "    print(f\"‚úì 3D animation found: result_{file_name}_256.mp4\")\n",
        "else:\n",
        "    print(f\"‚úó 3D animation not found\")\n",
        "\n",
        "# Get file size information for the main .obj file\n",
        "if os.path.exists(obj_path):\n",
        "    file_size = os.path.getsize(obj_path)\n",
        "    file_size_mb = file_size / (1024 * 1024)\n",
        "    print(f\"üìä 3D model size: {file_size_mb:.2f} MB\")\n",
        "\n",
        "# Download all available files\n",
        "if files_to_download:\n",
        "    print(f\"\\nüì• Downloading {len(files_to_download)} file(s)...\")\n",
        "\n",
        "    for file_desc, file_path in files_to_download:\n",
        "        try:\n",
        "            file_name_only = os.path.basename(file_path)\n",
        "            print(f\"Downloading {file_desc}: {file_name_only}...\")\n",
        "            files.download(file_path)\n",
        "            print(f\"‚úÖ Successfully downloaded: {file_name_only}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Failed to download {file_desc}: {str(e)}\")\n",
        "\n",
        "    print(f\"\\nüéâ Download process completed!\")\n",
        "\n",
        "else:\n",
        "    print(\"\\n‚ùå No output files found! The internet image processing may not have completed successfully.\")\n",
        "    print(\"\\nüîß Troubleshooting steps:\")\n",
        "    print(\"1. Verify the internet image processing script ran completely\")\n",
        "    print(\"2. Check if the image URL was valid and accessible\")\n",
        "    print(\"3. Ensure the pose estimation detected a human figure\")\n",
        "    print(\"4. Confirm PIFuHD processing completed without errors\")\n",
        "\n",
        "    # Enhanced debugging - show directory structure\n",
        "    print(f\"\\nüìÅ Checking results directory structure:\")\n",
        "\n",
        "    if os.path.exists('/content/pifuhd/results/'):\n",
        "        print(\"Results directory exists. Contents:\")\n",
        "        for root, dirs, files in os.walk('/content/pifuhd/results/'):\n",
        "            level = root.replace('/content/pifuhd/results/', '').count(os.sep)\n",
        "            indent = ' ' * 2 * level\n",
        "            print(f'{indent}{os.path.basename(root)}/')\n",
        "            subindent = ' ' * 2 * (level + 1)\n",
        "            for file in files:\n",
        "                if file.endswith(('.obj', '.png', '.mp4')):\n",
        "                    print(f'{subindent}üìÑ {file}')\n",
        "    else:\n",
        "        print(\"‚ùå Results directory not found!\")\n",
        "\n",
        "    # Check sample images directory\n",
        "    if os.path.exists('/content/pifuhd/sample_images/'):\n",
        "        print(f\"\\nüìÅ Sample images directory contents:\")\n",
        "        for file in os.listdir('/content/pifuhd/sample_images/'):\n",
        "            print(f\"  üìÑ {file}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üåê Internet Image 3D Model Download Complete!\")\n",
        "print(\"=\"*60)\n",
        "print(\"üí° Tip: You can view .obj files in 3D modeling software like:\")\n",
        "print(\"   ‚Ä¢ Blender (free)\")\n",
        "print(\"   ‚Ä¢ MeshLab (free)\")\n",
        "print(\"   ‚Ä¢ 3D Viewer (Windows)\")\n",
        "print(\"   ‚Ä¢ Online viewers like viewstl.com\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYgb88lLy3c_"
      },
      "source": [
        "# **Using From Desktop**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cOWhx_lIkna_"
      },
      "outputs": [],
      "source": [
        "#@title **Upload Image From Local Desktop**\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from google.colab import files\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Step 1: Set up paths\n",
        "SAMPLE_IMAGES_PATH = '/content/pifuhd/sample_images'\n",
        "RESULTS_PATH = '/content/pifuhd/results/pifuhd_final/recon'\n",
        "CHECKPOINT_PATH = '/content/lightweight-human-pose-estimation.pytorch/checkpoint_iter_370000.pth'\n",
        "\n",
        "# Clean up previous results\n",
        "print(\"Cleaning up previous results...\")\n",
        "os.system(f'rm -rf {SAMPLE_IMAGES_PATH}')\n",
        "os.makedirs(SAMPLE_IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "# Step 2: Upload Image\n",
        "print(\"Upload your image file\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "if not uploaded:\n",
        "    raise ValueError(\"No file uploaded. Please upload an image.\")\n",
        "\n",
        "filename = list(uploaded.keys())[0]\n",
        "image_path = f\"./{filename}\"\n",
        "\n",
        "# Check if file exists and can be read\n",
        "if not os.path.exists(image_path):\n",
        "    raise FileNotFoundError(f\"Uploaded file not found at {image_path}\")\n",
        "\n",
        "# Save uploaded image to the sample images folder\n",
        "img = cv2.imread(image_path)\n",
        "\n",
        "if img is None:\n",
        "    raise ValueError(f\"Could not read image from {image_path}. Please check if it's a valid image file.\")\n",
        "\n",
        "# Save with consistent naming\n",
        "target_image_path = f\"{SAMPLE_IMAGES_PATH}/webImg.png\"\n",
        "cv2.imwrite(target_image_path, img)\n",
        "\n",
        "# Clean up original uploaded file\n",
        "os.remove(image_path)\n",
        "\n",
        "# Update paths to use the consistent naming\n",
        "image_path = target_image_path\n",
        "image_dir = os.path.dirname(image_path)\n",
        "file_name = os.path.splitext(os.path.basename(image_path))[0]\n",
        "\n",
        "# Output paths\n",
        "obj_path = f\"{RESULTS_PATH}/result_{file_name}_256.obj\"\n",
        "out_img_path = f\"{RESULTS_PATH}/result_{file_name}_256.png\"\n",
        "video_path = f\"{RESULTS_PATH}/result_{file_name}_256.mp4\"\n",
        "video_display_path = f\"/content/pifuhd/results/pifuhd_final/result_{file_name}_256_display.mp4\"\n",
        "\n",
        "# Step 3: Setup and download checkpoint if needed\n",
        "print(\"Setting up Lightweight Human Pose Estimation...\")\n",
        "os.chdir('/content/lightweight-human-pose-estimation.pytorch/')\n",
        "\n",
        "# Check if checkpoint exists, if not download it\n",
        "if not os.path.exists(CHECKPOINT_PATH):\n",
        "    print(\"Downloading checkpoint file...\")\n",
        "    os.system('wget https://download.01.org/opencv/openvino_training_extensions/models/human_pose_estimation/checkpoint_iter_370000.pth')\n",
        "else:\n",
        "    print(\"Checkpoint file already exists\")\n",
        "\n",
        "# Import required modules\n",
        "from models.with_mobilenet import PoseEstimationWithMobileNet\n",
        "from modules.load_state import load_state\n",
        "from modules.keypoints import extract_keypoints, group_keypoints\n",
        "from modules.pose import Pose\n",
        "import demo\n",
        "\n",
        "# Fixed get_rect function with proper numpy compatibility\n",
        "def get_rect(net, images, height_size):\n",
        "    net = net.eval()\n",
        "    stride = 8\n",
        "    upsample_ratio = 4\n",
        "    num_keypoints = Pose.num_kpts\n",
        "\n",
        "    for image in images:\n",
        "        rect_path = image.replace('.%s' % (image.split('.')[-1]), '_rect.txt')\n",
        "        img = cv2.imread(image, cv2.IMREAD_COLOR)\n",
        "        orig_img = img.copy()\n",
        "        heatmaps, pafs, scale, pad = demo.infer_fast(net, img, height_size, stride, upsample_ratio, cpu=False)\n",
        "\n",
        "        total_keypoints_num = 0\n",
        "        all_keypoints_by_type = []\n",
        "        for kpt_idx in range(num_keypoints):  # 19th for bg\n",
        "            total_keypoints_num += extract_keypoints(heatmaps[:, :, kpt_idx], all_keypoints_by_type, total_keypoints_num)\n",
        "\n",
        "        pose_entries, all_keypoints = group_keypoints(all_keypoints_by_type, pafs)\n",
        "        for kpt_id in range(all_keypoints.shape[0]):\n",
        "            all_keypoints[kpt_id, 0] = (all_keypoints[kpt_id, 0] * stride / upsample_ratio - pad[1]) / scale\n",
        "            all_keypoints[kpt_id, 1] = (all_keypoints[kpt_id, 1] * stride / upsample_ratio - pad[0]) / scale\n",
        "\n",
        "        current_poses = []\n",
        "        rects = []\n",
        "        for n in range(len(pose_entries)):\n",
        "            if len(pose_entries[n]) == 0:\n",
        "                continue\n",
        "\n",
        "            pose_keypoints = np.ones((num_keypoints, 2), dtype=np.int32) * -1  # Fixed: np.int -> np.int32\n",
        "            valid_keypoints = []\n",
        "            for kpt_id in range(num_keypoints):\n",
        "                if pose_entries[n][kpt_id] != -1.0:  # keypoint was found\n",
        "                    pose_keypoints[kpt_id, 0] = int(all_keypoints[int(pose_entries[n][kpt_id]), 0])\n",
        "                    pose_keypoints[kpt_id, 1] = int(all_keypoints[int(pose_entries[n][kpt_id]), 1])\n",
        "                    valid_keypoints.append([pose_keypoints[kpt_id, 0], pose_keypoints[kpt_id, 1]])\n",
        "\n",
        "            valid_keypoints = np.array(valid_keypoints)\n",
        "            if pose_entries[n][10] != -1.0 or pose_entries[n][13] != -1.0:\n",
        "                pmin = valid_keypoints.min(0)\n",
        "                pmax = valid_keypoints.max(0)\n",
        "                center = (0.5 * (pmax[:2] + pmin[:2])).astype(np.int32)  # Fixed: np.int -> np.int32\n",
        "                radius = int(0.65 * max(pmax[0]-pmin[0], pmax[1]-pmin[1]))\n",
        "            elif pose_entries[n][10] == -1.0 and pose_entries[n][13] == -1.0 and pose_entries[n][8] != -1.0 and pose_entries[n][11] != -1.0:\n",
        "                # if leg is missing, use pelvis to get cropping\n",
        "                center = (0.5 * (pose_keypoints[8] + pose_keypoints[11])).astype(np.int32)  # Fixed: np.int -> np.int32\n",
        "                radius = int(1.45*np.sqrt(((center[None,:] - valid_keypoints)**2).sum(1)).max(0))\n",
        "                center[1] += int(0.05*radius)\n",
        "            else:\n",
        "                center = np.array([img.shape[1]//2, img.shape[0]//2])\n",
        "                radius = max(img.shape[1]//2, img.shape[0]//2)\n",
        "\n",
        "            x1 = center[0] - radius\n",
        "            y1 = center[1] - radius\n",
        "            rects.append([x1, y1, 2*radius, 2*radius])\n",
        "\n",
        "        np.savetxt(rect_path, np.array(rects), fmt='%d')\n",
        "\n",
        "# Load the network with checkpoint\n",
        "print(\"Loading pose estimation model...\")\n",
        "net = PoseEstimationWithMobileNet()\n",
        "checkpoint = torch.load(CHECKPOINT_PATH, map_location='cpu')\n",
        "load_state(net, checkpoint)\n",
        "\n",
        "# Run pose estimation\n",
        "print(\"Running pose estimation...\")\n",
        "get_rect(net.cuda(), [image_path], 512)\n",
        "\n",
        "# Step 4: Run PIFuHD\n",
        "print(\"Running PIFuHD for 3D reconstruction...\")\n",
        "os.chdir('/content/pifuhd/')\n",
        "os.makedirs(RESULTS_PATH, exist_ok=True)\n",
        "\n",
        "# Warning: all images with the corresponding rectangle files under -i will be processed.\n",
        "os.system(f'python -m apps.simple_test -r 256 --use_rect -i {image_dir}')\n",
        "# 256 is the maximum resolution that can fit into Google Colab.\n",
        "# If you want to reconstruct a higher-resolution mesh, please try with your own machine.\n",
        "\n",
        "# Step 5: Generate video output\n",
        "print(\"Generating video output...\")\n",
        "clear_output()\n",
        "\n",
        "# Import video generation utilities\n",
        "from lib.colab_util import generate_video_from_obj, set_renderer, video\n",
        "\n",
        "# Render video\n",
        "renderer = set_renderer()\n",
        "generate_video_from_obj(obj_path, out_img_path, video_path, renderer)\n",
        "\n",
        "# Convert video for display (we cannot play a mp4 video generated by cv2)\n",
        "os.system(f'ffmpeg -i {video_path} -vcodec libx264 {video_display_path} -y -loglevel quiet')\n",
        "\n",
        "# Display the final video\n",
        "print(\"3D reconstruction complete! Playing result video...\")\n",
        "video(video_display_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "RxlEpL4by7Xp"
      },
      "outputs": [],
      "source": [
        "#@title **Download 3D Model (.obj file) and Results**\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "# Define paths\n",
        "RESULTS_PATH = '/content/pifuhd/results/pifuhd_final/recon'\n",
        "file_name = 'webImg'  # This should match the naming from the processing script\n",
        "\n",
        "# Define all possible output files\n",
        "obj_path = f'{RESULTS_PATH}/result_{file_name}_256.obj'\n",
        "png_path = f'{RESULTS_PATH}/result_{file_name}_256.png'\n",
        "video_path = f'{RESULTS_PATH}/result_{file_name}_256.mp4'\n",
        "video_display_path = f'/content/pifuhd/results/pifuhd_final/result_{file_name}_256_display.mp4'\n",
        "\n",
        "print(\"Checking available files...\")\n",
        "\n",
        "# Check which files exist and download them\n",
        "files_to_download = []\n",
        "\n",
        "if os.path.exists(obj_path):\n",
        "    files_to_download.append(('3D Model (.obj)', obj_path))\n",
        "    print(f\"‚úì 3D model found: {obj_path}\")\n",
        "else:\n",
        "    print(f\"‚úó 3D model not found: {obj_path}\")\n",
        "\n",
        "if os.path.exists(png_path):\n",
        "    files_to_download.append(('Rendered Image (.png)', png_path))\n",
        "    print(f\"‚úì Rendered image found: {png_path}\")\n",
        "else:\n",
        "    print(f\"‚úó Rendered image not found: {png_path}\")\n",
        "\n",
        "if os.path.exists(video_display_path):\n",
        "    files_to_download.append(('3D Animation (.mp4)', video_display_path))\n",
        "    print(f\"‚úì 3D animation found: {video_display_path}\")\n",
        "elif os.path.exists(video_path):\n",
        "    files_to_download.append(('3D Animation (.mp4)', video_path))\n",
        "    print(f\"‚úì 3D animation found: {video_path}\")\n",
        "else:\n",
        "    print(f\"‚úó 3D animation not found\")\n",
        "\n",
        "# Download all available files\n",
        "if files_to_download:\n",
        "    print(f\"\\nDownloading {len(files_to_download)} file(s)...\")\n",
        "    for file_desc, file_path in files_to_download:\n",
        "        try:\n",
        "            print(f\"Downloading {file_desc}...\")\n",
        "            files.download(file_path)\n",
        "            print(f\"‚úì Successfully downloaded: {os.path.basename(file_path)}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚úó Failed to download {file_desc}: {str(e)}\")\n",
        "else:\n",
        "    print(\"\\n‚ùå No output files found! Please make sure the PIFuHD processing completed successfully.\")\n",
        "    print(\"\\nTroubleshooting:\")\n",
        "    print(\"1. Check if the processing script ran without errors\")\n",
        "    print(\"2. Verify the image was uploaded and processed correctly\")\n",
        "    print(\"3. Make sure the pose estimation step completed successfully\")\n",
        "\n",
        "    # List all files in the results directory for debugging\n",
        "    if os.path.exists(RESULTS_PATH):\n",
        "        print(f\"\\nFiles found in {RESULTS_PATH}:\")\n",
        "        for file in os.listdir(RESULTS_PATH):\n",
        "            print(f\"  - {file}\")\n",
        "    else:\n",
        "        print(f\"\\nResults directory does not exist: {RESULTS_PATH}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Download complete!\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9J7I_6YkMhgC"
      },
      "source": [
        "# **Refrence**\n",
        "\n",
        "github:- https://github.com/garvsharmxa/\n",
        "\n",
        "Methods refrence's:- https://shunsukesaito.github.io/PIFuHD/\n",
        "\n",
        "Background Remover :- https://www.remove.bg/\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}